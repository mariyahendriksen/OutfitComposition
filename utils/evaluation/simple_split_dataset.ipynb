{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook shows how you could split Fashion outfits file in order to have train and test datasets to experiment with your model.\n",
    "\n",
    "**Disclaimer**: The process used here is alway simple than the one we used to generate the test files for the leaderboard, but you could expect that some tricks used here (like dealing with products as a set, or generating candidates based on entire product_id list) are also used on the leaderboard files.\n",
    "\n",
    "This code takes about 40 minutes to run in a common notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "print(datetime.datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "full_outfits = pd.read_parquet(\"../data/manual_outfits.parquet\")\n",
    "full_outfits.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To generate more examples given an particular outfit, one way is shuffing the products, remember that outfits are sets of products. This step is here just to ilustrate this possibility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.random import permutation\n",
    "\n",
    "full_outfits[\"products_shuffled\"] = full_outfits.apply(lambda row: permutation(row[\"products\"]).tolist(), axis=1)\n",
    "full_outfits.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To generate a train example to use in your model, you could split a outfit in incomplete_outfit and missing_product."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_outfits[\"incomplete_outfit\"] = full_outfits.apply(lambda row: row[\"products_shuffled\"][:-1], axis=1)\n",
    "full_outfits[\"missing_product\"] = full_outfits.apply(lambda row: row[\"products_shuffled\"][-1], axis=1)\n",
    "full_outfits.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "items_metadata = pd.read_parquet(\"../data/products.parquet\")\n",
    "items_metadata = items_metadata[\"product_id\"]\n",
    "items_metadata.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One way to generate candidates is to sample then from all product_id in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import randint\n",
    "\n",
    "def candidates(row, minc=8, maxc=40):\n",
    "    n = randint(minc, maxc)\n",
    "    c = items_metadata.sample(n).unique().tolist()\n",
    "    c.append(row[\"missing_product\"])\n",
    "    return list(set(c))\n",
    "\n",
    "full_outfits[\"candidates\"] = full_outfits.apply(lambda row: candidates(row), axis=1)\n",
    "full_outfits.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A example of split on 80% for training and 20% for test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = full_outfits.sample(frac=0.8)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = full_outfits[~full_outfits.outfit_id.isin(set(train[\"outfit_id\"].values.tolist()))]\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_input = test[[\"outfit_id\", \"incomplete_outfit\", \"candidates\"]]\n",
    "test_input.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_output = test[[\"outfit_id\", \"missing_product\"]]\n",
    "test_output.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "unique_name = int(time.time())\n",
    "train.to_parquet(f\"../data/manual_outfits_train_{unique_name}.parquet\")\n",
    "test_input.to_parquet(f\"../data/manual_outfits_testinput_{unique_name}.parquet\")\n",
    "test_output.to_csv(f\"../data/manual_outfits_testoutput_{unique_name}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(datetime.datetime.now())"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
